{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHcNtFa8sZqTaRTUc/Jrwy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kim-Yeon-Jun/PyTorch/blob/main/pytorch_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예제 : 문자RNN으로 성씨 생성하기\n",
        "각 타임 스텝에서 RNN이 성씨에 포함될 수 있는 문자 집합에 대한 확률 분포를 계산한다는 의미\\\n",
        "성씨 생성 모델 2가지\\\n",
        "조건이 있는 SurnameGenerationModel : 국적 정보 사용O\\\n",
        "조건이 없는 SurnameGenerationModel : 국적 정보 사용X"
      ],
      "metadata": {
        "id": "c4__D2n2d5iq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kChsR4lXdPHA"
      },
      "outputs": [],
      "source": [
        "#시퀀스 예측 작업을 위한 SurnameDataset.__getitem__() 메서드\n",
        "class SurnameDataset(Dataset):\n",
        "  @classmethod\n",
        "  def load_dataset_and_make_vetorizer(cls, surname_csv):\n",
        "    \"\"\"데이터셋을 로드하고 새로운 Vectorizer를 만듦\n",
        "      매개변수 :\n",
        "        surname_csv (str) : 데이터셋의 위치\n",
        "      반환값 :\n",
        "        SurnameDataset 객체\n",
        "    \"\"\"\n",
        "\n",
        "    surname_df = pd.read_csv(surname_csv)\n",
        "    return cls(surname_df, SurnameVecotrizer.from_dataframe(surname_df))\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    \"\"\" 파이토치 데이터셋의 주요 진입 메서드\n",
        "\n",
        "    매개변수 :\n",
        "      index(int) : 데이터 포인트에 대한 인덱스\n",
        "\n",
        "    반환값 :\n",
        "      데이터 포인트 (x_data, y_target, class_index)를 담은 딕셔너리\n",
        "\n",
        "    \"\"\"\n",
        "    row = self._target_df.iloc[index]\n",
        "    from_vector, to_vector = \\\n",
        "      self._vectorizer.vectorize(row.surname, self._max_seq_length)\n",
        "\n",
        "    nationality_index = \\\n",
        "      self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "\n",
        "    return {'x_data' : from_vector,\n",
        "            'y_target' : to_vector,\n",
        "            'class_index' : nationality_index}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#시퀀스 예측을 위한 SurnameVecotrizer.vectorizer()코드\n",
        "class SurnameVectorizer(object):\n",
        "    \"\"\" 어휘 사전을 생성하고 관리합니다 \"\"\"\n",
        "\n",
        "    def vectorize(self, surname, vector_length=-1):\n",
        "        \"\"\" 성씨를 샘플과 타깃 벡터로 변환합니다\n",
        "        성씨 벡터를 두 개의 벡터 surname[:-1]와 surname[1:]로 나누어 출력합니다.\n",
        "        각 타임스텝에서 첫 번째 벡터가 샘플이고 두 번째 벡터가 타깃입니다.\n",
        "\n",
        "        매개변수:\n",
        "            surname (str): 벡터로 변경할 성씨\n",
        "            vector_length (int): 인덱스 벡터의 길이를 맞추기 위한 매개변수\n",
        "        반환값:\n",
        "            튜플: (from_vector, to_vector)\n",
        "                from_vector (numpy.ndarray): 샘플 벡터\n",
        "                to_vector (numpy.ndarray): 타깃 벡터 vector\n",
        "        \"\"\"\n",
        "        indices = [self.char_vocab.begin_seq_index]\n",
        "        indices.extend(self.char_vocab.lookup_token(token) for token in surname)\n",
        "        indices.append(self.char_vocab.end_seq_index)\n",
        "\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices) - 1\n",
        "\n",
        "        from_vector = np.empty(vector_length, dtype=np.int64)\n",
        "        from_indices = indices[:-1]\n",
        "        from_vector[:len(from_indices)] = from_indices\n",
        "        from_vector[len(from_indices):] = self.char_vocab.mask_index\n",
        "\n",
        "        to_vector = np.empty(vector_length, dtype=np.int64)\n",
        "        to_indices = indices[1:]\n",
        "        to_vector[:len(to_indices)] = to_indices\n",
        "        to_vector[len(to_indices):] = self.char_vocab.mask_index\n",
        "\n",
        "        return from_vector, to_vector\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, surname_df):\n",
        "        \"\"\"데이터셋 데이터프레임으로 객체를 초기화합니다\n",
        "\n",
        "        매개변수:\n",
        "            surname_df (pandas.DataFrame): 성씨 데이터셋\n",
        "        반환값:\n",
        "            SurnameVectorizer 객체\n",
        "        \"\"\"\n",
        "        char_vocab = SequenceVocabulary()\n",
        "        nationality_vocab = Vocabulary()\n",
        "\n",
        "        for index, row in surname_df.iterrows():\n",
        "            for char in row.surname:\n",
        "                char_vocab.add_token(char)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "\n",
        "        return cls(char_vocab, nationality_vocab)"
      ],
      "metadata": {
        "id": "qTKmXVb1hmhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 1 : 조건이 없는 SurnameGenerationModel\n",
        "class SurnameGenerationModel(nn.Module):\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size,\n",
        "                 batch_first=True, padding_idx=0, dropout_p=0.5):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            char_embedding_size (int): 문자 임베딩 크기\n",
        "            char_vocab_size (int): 임베딩될 문자 개수\n",
        "            rnn_hidden_size (int): RNN의 은닉 상태 크기\n",
        "            batch_first (bool): 0번째 차원이 배치인지 시퀀스인지 나타내는 플래그\n",
        "            padding_idx (int): 텐서 패딩을 위한 인덱스;\n",
        "                torch.nn.Embedding를 참고하세요\n",
        "            dropout_p (float): 드롭아웃으로 활성화 출력을 0으로 만들 확률\n",
        "        \"\"\"\n",
        "        super(SurnameGenerationModel, self).__init__()\n",
        "\n",
        "        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n",
        "                                     embedding_dim=char_embedding_size,\n",
        "                                     padding_idx=padding_idx)\n",
        "\n",
        "        self.rnn = nn.GRU(input_size=char_embedding_size,\n",
        "                          hidden_size=rnn_hidden_size,\n",
        "                          batch_first=batch_first)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=rnn_hidden_size,\n",
        "                            out_features=char_vocab_size)\n",
        "\n",
        "        self._dropout_p = dropout_p\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"모델의 정방향 계산\n",
        "\n",
        "        매개변수:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서\n",
        "                x_in.shape는 (batch, input_dim)입니다.\n",
        "            apply_softmax (bool): 소프트맥스 활성화를 위한 플래그로 훈련시에는 False가 되어야 합니다.\n",
        "        반환값:\n",
        "            결과 텐서. tensor.shape는 (batch, char_vocab_size)입니다.\n",
        "        \"\"\"\n",
        "        x_embedded = self.char_emb(x_in)\n",
        "\n",
        "        y_out, _ = self.rnn(x_embedded)\n",
        "\n",
        "        batch_size, seq_size, feat_size = y_out.shape\n",
        "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
        "\n",
        "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "\n",
        "        new_feat_size = y_out.shape[-1]\n",
        "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
        "\n",
        "        return y_out"
      ],
      "metadata": {
        "id": "Vsb3GiOXhmlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 2 : 조건이 있는 SurnameGenerationModel\n",
        "class SurnameGenerationModel(nn.Module):\n",
        "    def __init__(self, char_embedding_size, char_vocab_size, num_nationalities,\n",
        "                 rnn_hidden_size, batch_first=True, padding_idx=0, dropout_p=0.5):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            char_embedding_size (int): 문자 임베딩 크기\n",
        "            char_vocab_size (int): 임베딩될 문자 개수\n",
        "            rnn_hidden_size (int): RNN의 은닉 상태 크기\n",
        "            batch_first (bool): 0번째 차원이 배치인지 시퀀스인지 나타내는 플래그\n",
        "            padding_idx (int): 텐서 패딩을 위한 인덱스;\n",
        "                torch.nn.Embedding를 참고하세요\n",
        "            dropout_p (float): 드롭아웃으로 활성화 출력을 0으로 만들 확률\n",
        "        \"\"\"\n",
        "        super(SurnameGenerationModel, self).__init__()\n",
        "\n",
        "        self.char_emb = nn.Embedding(num_embeddings=char_vocab_size,\n",
        "                                     embedding_dim=char_embedding_size,\n",
        "                                     padding_idx=padding_idx)\n",
        "\n",
        "        self.nation_emb = nn.Embedding(num_embeddings=num_nationalities,\n",
        "                                       embedding_dim=rnn_hidden_size)\n",
        "\n",
        "        self.rnn = nn.GRU(input_size=char_embedding_size,\n",
        "                          hidden_size=rnn_hidden_size,\n",
        "                          batch_first=batch_first)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=rnn_hidden_size,\n",
        "                            out_features=char_vocab_size)\n",
        "\n",
        "        self._dropout_p = dropout_p\n",
        "\n",
        "    def forward(self, x_in, nationality_index, apply_softmax=False):\n",
        "        \"\"\"모델의 정방향 계산\n",
        "\n",
        "        매개변수:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서\n",
        "                x_in.shape는 (batch, max_seq_size)입니다.\n",
        "            nationality_index (torch.Tensor): 각 데이터 포인트를 위한 국적 인덱스\n",
        "                RNN의 은닉 상태를 초기화하는데 사용합니다.\n",
        "            apply_softmax (bool): 소프트맥스 활성화를 위한 플래그로 훈련시에는 False가 되어야 합니다.\n",
        "        반환값:\n",
        "            결과 텐서. tensor.shape는 (batch, char_vocab_size)입니다.\n",
        "        \"\"\"\n",
        "        x_embedded = self.char_emb(x_in)\n",
        "\n",
        "        # hidden_size: (num_layers * num_directions, batch_size, rnn_hidden_size)\n",
        "        nationality_embedded = self.nation_emb(nationality_index).unsqueeze(0)\n",
        "\n",
        "        y_out, _ = self.rnn(x_embedded, nationality_embedded)\n",
        "\n",
        "        batch_size, seq_size, feat_size = y_out.shape\n",
        "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
        "\n",
        "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "\n",
        "        new_feat_size = y_out.shape[-1]\n",
        "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
        "\n",
        "        return y_out"
      ],
      "metadata": {
        "id": "maLcYngJh4p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3차원 텐서와 시퀀스 손실 계산\n",
        "def normalize_sizes(y_pred, y_true):\n",
        "  \"\"\"텐서 크기 정규화\n",
        "\n",
        "  매개변수 :\n",
        "    y_pred (torch.Tensor) : 모델의 출력\n",
        "      3차원 텐서이면 행렬로 변환함\n",
        "    y_true(torch.Tensor) : 타깃 예측\n",
        "      행렬이명 벡터로 변환함\n",
        "\n",
        "  \"\"\"\n",
        "  if len(y_pred.size()) == 3 :\n",
        "    y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
        "  if len(y_true.size()) == 2 :\n",
        "    y_true = y_true.contiguous().view(-1)\n",
        "  return y_pred, y_true\n",
        "\n",
        "def sequence_loss(y_pred, y_true, mask_index):\n",
        "  y_pred, y_true = normalize_size(y_pred, y_true)\n",
        "  return F.cross_entropy(y_pred, y_true, ignore_index = mask_index)"
      ],
      "metadata": {
        "id": "3f7C21nTnKLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#성씨 생성을 위한 파라미터\n",
        "args = Namespace(\n",
        "    # 날짜와 경로 정보\n",
        "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"model_storage/ch7/model2_conditioned_surname_generation\",\n",
        "    # 모델 하이퍼파라미터\n",
        "    char_embedding_size=32,\n",
        "    rnn_hidden_size=32,\n",
        "    # 훈련 하이퍼파라미터\n",
        "    seed=1337,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=128,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    # 실행 옵션\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False,\n",
        ")"
      ],
      "metadata": {
        "id": "9yX3hObMo6QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#조건이 없는 생성 모델의 샘플링\n",
        "def sample_from_model(model, vectorizer, num_samples=1, sample_size=20,\n",
        "                      temperature=1.0):\n",
        "    \"\"\"모델이 만든 인덱스 시퀀스를 샘플링합니다.\n",
        "\n",
        "    매개변수:\n",
        "        model (SurnameGenerationModel): 훈련 모델\n",
        "        vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "        num_samples (int): 샘플 개수\n",
        "        sample_size (int): 샘플의 최대 길이\n",
        "        temperature (float): 무작위성 정도\n",
        "            0.0 < temperature < 1.0 이면 최대 값을 선택할 가능성이 높습니다\n",
        "            temperature > 1.0 이면 균등 분포에 가깝습니다\n",
        "    반환값:\n",
        "        indices (torch.Tensor): 인덱스 행렬\n",
        "        shape = (num_samples, sample_size)\n",
        "    \"\"\"\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index\n",
        "                       for _ in range(num_samples)]\n",
        "    begin_seq_index = torch.tensor(begin_seq_index,\n",
        "                                   dtype=torch.int64).unsqueeze(dim=1)\n",
        "    indices = [begin_seq_index]\n",
        "    h_t = None\n",
        "\n",
        "    for time_step in range(sample_size):\n",
        "        x_t = indices[time_step]\n",
        "        x_emb_t = model.char_emb(x_t)\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\n",
        "    return indices"
      ],
      "metadata": {
        "id": "BOLjNhCnvDUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#샘플링된 인덱스를 성씨 문자열로 매핑합니다\n",
        "def decode_samples(sampled_indices, vectorizer):\n",
        "    \"\"\"인덱스를 성씨 문자열로 변환합니다\n",
        "\n",
        "    매개변수:\n",
        "        sampled_indices (torch.Tensor): `sample_from_model` 함수에서 얻은 인덱스\n",
        "        vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "    \"\"\"\n",
        "    decoded_surnames = []\n",
        "    vocab = vectorizer.char_vocab\n",
        "\n",
        "    for sample_index in range(sampled_indices.shape[0]):\n",
        "        surname = \"\"\n",
        "        for time_step in range(sampled_indices.shape[1]):\n",
        "            sample_item = sampled_indices[sample_index, time_step].item()\n",
        "            if sample_item == vocab.begin_seq_index:\n",
        "                continue\n",
        "            elif sample_item == vocab.end_seq_index:\n",
        "                break\n",
        "            else:\n",
        "                surname += vocab.lookup_index(sample_item)\n",
        "        decoded_surnames.append(surname)\n",
        "    return decoded_surnames"
      ],
      "metadata": {
        "id": "i6AfRKSDvDSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#조건이 없는 모델에서 샘플링하기\n",
        "samples = sample_from_model(unconditioned_model, vectorizer, num_samples=10)\n",
        "decode_samples(samples, vectorizer)"
      ],
      "metadata": {
        "id": "pzGiU_o-vDPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#조건이 있는 모델의 샘플링\n",
        "def sample_from_model(model, vectorizer, nationalities, sample_size=20,\n",
        "                      temperature=1.0):\n",
        "    \"\"\"모델이 만든 인덱스 시퀀스를 샘플링합니다.\n",
        "\n",
        "    매개변수:\n",
        "        model (SurnameGenerationModel): 훈련 모델\n",
        "        vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "        nationalities (list): 국적을 나타내는 정수 리스트\n",
        "        sample_size (int): 샘플의 최대 길이\n",
        "        temperature (float): 무작위성 정도\n",
        "            0.0 < temperature < 1.0 이면 최대 값을 선택할 가능성이 높습니다\n",
        "            temperature > 1.0 이면 균등 분포에 가깝습니다\n",
        "    반환값:\n",
        "        indices (torch.Tensor): 인덱스 행렬\n",
        "        shape = (num_samples, sample_size)\n",
        "    \"\"\"\n",
        "    num_samples = len(nationalities)\n",
        "    begin_seq_index = [vectorizer.char_vocab.begin_seq_index\n",
        "                       for _ in range(num_samples)]\n",
        "    begin_seq_index = torch.tensor(begin_seq_index,\n",
        "                                   dtype=torch.int64).unsqueeze(dim=1)\n",
        "    indices = [begin_seq_index]\n",
        "    nationality_indices = torch.tensor(nationalities, dtype=torch.int64).unsqueeze(dim=0)\n",
        "    h_t = model.nation_emb(nationality_indices)\n",
        "\n",
        "    for time_step in range(sample_size):\n",
        "        x_t = indices[time_step]\n",
        "        x_emb_t = model.char_emb(x_t)\n",
        "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
        "        prediction_vector = model.fc(rnn_out_t.squeeze(dim=1))\n",
        "        probability_vector = F.softmax(prediction_vector / temperature, dim=1)\n",
        "        indices.append(torch.multinomial(probability_vector, num_samples=1))\n",
        "    indices = torch.stack(indices).squeeze().permute(1, 0)\n",
        "    return indices"
      ],
      "metadata": {
        "id": "_W51vsfqnKTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#조건이 있는 SurnameGenerationModel의 샘플링\n",
        "for index in range(len(vectorizer.nationality_vocab)):\n",
        "  nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "\n",
        "  print(\"{} 샘플 :\".format(nationality))\n",
        "\n",
        "  sampled_indices = sample_from_model(model = conditioned_model,\n",
        "                                      vectorizer=vectorizer,\n",
        "                                      nationalities=[index] *3\n",
        "                                      temperature = 0.7)\n",
        "  for sampled_surname in decode_samples(sampled_indices,\n",
        "                                        vectorizer):\n",
        "    print(\"- \" + sampled_surname)"
      ],
      "metadata": {
        "id": "Q0QXVUe1_VJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}